{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InceptionV4.ipynb의 사본","provenance":[],"collapsed_sections":[],"mount_file_id":"1poFTfkOpxosVtgTbMZhKWrjMCG5IiA4Y","authorship_tag":"ABX9TyPJrNm8ltFShQSgXzI5TzZn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"42aea894cfa24564ae95872d68c5f1aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_96c0854c4c2c4858a289afeecc4da16d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_93115b68cd88462dad03b34f2ae0099f","IPY_MODEL_16a13fbc561d4b2cb318042d7256eacb"]}},"96c0854c4c2c4858a289afeecc4da16d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93115b68cd88462dad03b34f2ae0099f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_369b4ed7b70a48659ac8345ea36c764f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8769ef7b2c44124b5a5c881a975c8a6"}},"16a13fbc561d4b2cb318042d7256eacb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_63f8f28c2b164377a965e7ae1e34d887","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:03&lt;00:00, 46017207.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74496719b1774851a90dd9e35d630fdd"}},"369b4ed7b70a48659ac8345ea36c764f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8769ef7b2c44124b5a5c881a975c8a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63f8f28c2b164377a965e7ae1e34d887":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"74496719b1774851a90dd9e35d630fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"I5JnD9XFO6dd","executionInfo":{"status":"ok","timestamp":1615961193154,"user_tz":-540,"elapsed":4437,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","import torchvision.datasets as dsets\r\n","import torchvision.transforms as T\r\n","import torch.optim as optim\r\n","import torchvision.models as models"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDgvpvC3OnBd","executionInfo":{"status":"ok","timestamp":1615961193397,"user_tz":-540,"elapsed":4671,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":["import argparse\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","\r\n","class InceptionV4(nn.Module):\r\n","    def __init__(self):\r\n","        super(InceptionV4,self).__init__()\r\n","        # valid padding -> no padding.\r\n","        # same padding -> using padding.\r\n","\r\n","        # 32x32x3 -> 16x16x\r\n","        self.stem = nn.Sequential(\r\n","            nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=2,padding=0),\r\n","            nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,),\r\n","            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding =1),\r\n","        )\r\n","        self.left1 = nn.MaxPool2d(kernel_size=3,stride=2)\r\n","        self.right1 = nn.Conv2d(in_channels=64,out_channels=96,kernel_size=3,stride=2)\r\n","\r\n","        self.left2 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=160,out_channels=64,kernel_size=1),\r\n","            nn.Conv2d(in_channels=64,out_channels=96,kernel_size=3,stride=1,padding=1)\r\n","        )\r\n","        self.right2 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=160,out_channels=64,kernel_size=1),\r\n","            # nn.Conv2d(in_channels=64,out_channels=64,kernel_size=(7,1)),\r\n","            # nn.Conv2d(in_channels=64,out_channels=64,kernel_size=(1,7)),\r\n","            nn.Conv2d(in_channels=64,out_channels=96,kernel_size=3,stride=1,padding=1),\r\n","        )\r\n","        self.left3 = nn.Conv2d(in_channels=192,out_channels=192,kernel_size=3,stride=1,padding=1)\r\n","        self.right3 = nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\r\n","\r\n","        self.inc_A = Inception_A(384)\r\n","        self.red_A = Reduction_A(384)\r\n","        self.inc_B = Inception_B(1024)\r\n","        self.red_B = Reduction_B(1024)\r\n","        self.inc_C = Inception_C(1536)\r\n","\r\n","        self.fc = nn.Linear(1536,10)\r\n","        self.sm = nn.Softmax(dim=1)\r\n","    def forward(self,x):\r\n","        x = self.stem(x)\r\n","        left1 = self.left1(x)\r\n","        right1 = self.right1(x)\r\n","\r\n","        concat1 = [left1,right1]\r\n","        concat1 = torch.cat(concat1,1)\r\n","        #Filter concat\r\n","        left2 = self.left2(concat1)\r\n","        right2 = self.right2(concat1)\r\n","        concat2 = [left2,right2]\r\n","        concat2 = torch.cat(concat2,1)\r\n","        #Filter concat\r\n","        left3 = self.left3(concat2)\r\n","        right3 = self.right3(concat2)\r\n","        concat3 = [left3,right3]\r\n","        concat3 = torch.cat(concat3,1)\r\n","        #Filter concat\r\n","        #### stem Finish###\r\n","        a = concat3\r\n","        for i in range(4):\r\n","            a = self.inc_A(concat3)\r\n","        a = self.red_A(a)\r\n","        for i in range(7):\r\n","            a = self.inc_B(a)\r\n","        a = self.red_B(a)\r\n","        for i in range(3):\r\n","            a = self.inc_C(a)\r\n","        a = F.adaptive_avg_pool2d(a,(1,1))\r\n","        a = F.dropout(a,p=0.8)\r\n","        a = a.view(a.size(0),-1)\r\n","        a = self.fc(a)\r\n","        a = self.sm(a)\r\n","        return a\r\n","\r\n","class Inception_A(nn.Module):\r\n","    def __init__(self,in_channels):\r\n","        super(Inception_A,self).__init__()\r\n","        self.layer1 = nn.Sequential(\r\n","            nn.AvgPool2d(kernel_size=3,stride=1,padding=1),\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=96,kernel_size=1,stride=1,padding=0)\r\n","        )\r\n","        self.layer2 = nn.Conv2d(in_channels=in_channels,out_channels=96,kernel_size=1,stride=1)\r\n","        self.layer3 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=64,kernel_size=1),\r\n","            nn.Conv2d(in_channels=64,out_channels=96,kernel_size=3,stride=1,padding=1),\r\n","        )\r\n","        self.layer4 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=64,kernel_size=1),\r\n","            nn.Conv2d(in_channels=64,out_channels=96,kernel_size=3,padding=1),\r\n","            nn.Conv2d(in_channels=96,out_channels=96,kernel_size=3,padding=1),\r\n","        )\r\n","    def forward(self,x):\r\n","        layer1 = self.layer1(x)\r\n","        layer2 = self.layer2(x)\r\n","        layer3 = self.layer3(x)\r\n","        layer4 = self.layer4(x)\r\n","        concat = [layer1,layer2,layer3,layer4]\r\n","        return torch.cat(concat,1)\r\n","# 7x1 대신 3x1 로 변경할 예정\r\n","class Inception_B(nn.Module):\r\n","    def __init__(self,in_channels):\r\n","        super(Inception_B,self).__init__()\r\n","        self.layer1 = nn.Sequential(\r\n","            nn.AvgPool2d(kernel_size=3,stride=1,padding=1),\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=128,kernel_size=1),\r\n","        )\r\n","        self.layer2 = nn.Conv2d(in_channels=in_channels,out_channels=384,kernel_size=1)\r\n","        self.layer3 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=192,kernel_size=1),\r\n","            nn.Conv2d(in_channels=192,out_channels=224,kernel_size=(1,3),padding=(0,1)),\r\n","            nn.Conv2d(in_channels=224,out_channels=256,kernel_size=(3,1),padding=(1,0)),\r\n","        )\r\n","        self.layer4 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=192,kernel_size=1),\r\n","            nn.Conv2d(in_channels=192,out_channels=192,kernel_size=(1,3),padding=(0,1)),\r\n","            nn.Conv2d(in_channels=192,out_channels=224,kernel_size=(3,1),padding=(1,0)),\r\n","            nn.Conv2d(in_channels=224,out_channels=224,kernel_size=(1,3),padding=(0,1)),\r\n","            nn.Conv2d(in_channels=224,out_channels=256,kernel_size=(3,1),padding=(1,0)),\r\n","        )\r\n","    def forward(self,x):\r\n","        layer1 = self.layer1(x)\r\n","        layer2 = self.layer2(x)\r\n","        layer3 = self.layer3(x)\r\n","        layer4 = self.layer4(x)\r\n","        concat = [layer1,layer2,layer3,layer4]\r\n","        return torch.cat(concat,1)\r\n","\r\n","class Inception_C(nn.Module):\r\n","    def __init__(self,in_channels):\r\n","        super(Inception_C,self).__init__()\r\n","        self.layer1 = nn.Sequential(\r\n","            nn.AvgPool2d(kernel_size=3,stride=1,padding=1),\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=256,kernel_size=1),\r\n","        )\r\n","        self.layer2= nn.Conv2d(in_channels=in_channels,out_channels=256,kernel_size=1)\r\n","        self.layer3_1 = nn.Conv2d(in_channels=in_channels,out_channels=384,kernel_size=1)\r\n","        self.layer3_2_left = nn.Conv2d(in_channels=384,out_channels=256,kernel_size=(1,3),padding=(0,1))\r\n","        self.layer3_2_right = nn.Conv2d(in_channels=384,out_channels=256,kernel_size=(3,1),padding=(1,0))\r\n","        self.layer4_1 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=384,kernel_size=1),\r\n","            nn.Conv2d(in_channels=384,out_channels=448,kernel_size=(1,3),padding=(0,1)),\r\n","            nn.Conv2d(in_channels=448,out_channels=512,kernel_size=(3,1),padding=(1,0)),\r\n","        )\r\n","        self.layer4_2_left = nn.Conv2d(in_channels=512,out_channels=256,kernel_size=(3,1),padding=(1,0))\r\n","        self.layer4_2_right = nn.Conv2d(in_channels=512,out_channels=256,kernel_size=(1,3),padding=(0,1))\r\n","\r\n","    def forward(self,x):\r\n","        layer1 = self.layer1(x)\r\n","        layer2 = self.layer2(x)\r\n","        layer3 = self.layer3_1(x)\r\n","        layer3_l = self.layer3_2_left(layer3)\r\n","        layer3_r = self.layer3_2_right(layer3)\r\n","        layer4 = self.layer4_1(x)\r\n","        layer4_l=self.layer4_2_left(layer4)\r\n","        layer4_r = self.layer4_2_right(layer4)\r\n","\r\n","        concat = [layer1,layer2,layer3_l,layer3_r,layer4_l,layer4_r]\r\n","        return torch.cat(concat,1)\r\n","# 11 -> 4\r\n","class Reduction_A(nn.Module):\r\n","    def __init__(self,in_channels):\r\n","        super(Reduction_A,self).__init__()\r\n","        self.layer1 = nn.MaxPool2d(kernel_size=3,stride=2,padding =0)\r\n","        self.layer2 = nn.Conv2d(in_channels=in_channels,out_channels=384,kernel_size=3,stride=2)\r\n","        self.layer3 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=192,kernel_size=1),\r\n","            nn.Conv2d(in_channels=192,out_channels=224,kernel_size=3,padding=1),\r\n","            nn.Conv2d(in_channels=224,out_channels=256,kernel_size=3,stride=2,padding=0)\r\n","        )\r\n","    def forward(self,x):\r\n","        layer1 = self.layer1(x)\r\n","        layer2 = self.layer2(x)\r\n","        layer3 = self.layer3(x)\r\n","        concat = [layer1,layer2,layer3]\r\n","        concat = torch.cat(concat,1)\r\n","        return concat\r\n","\r\n","# 4->2\r\n","class Reduction_B(nn.Module):\r\n","    def __init__(self,in_channels):\r\n","        super(Reduction_B,self).__init__()\r\n","        self.layer1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\r\n","        self.layer2 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=192,kernel_size=1),\r\n","            nn.Conv2d(in_channels=192,out_channels=192,kernel_size=3,stride=2,padding=1),\r\n","        )\r\n","        self.layer3 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=in_channels,out_channels=256,kernel_size=1),\r\n","            nn.Conv2d(in_channels=256,out_channels=320,kernel_size=3,stride=2,padding=1)\r\n","        )\r\n","    def forward(self,x):\r\n","        layer1 = self.layer1(x)\r\n","        layer2 = self.layer2(x)\r\n","        layer3 = self.layer3(x)\r\n","        \r\n","        concat = [layer1,layer2,layer3]\r\n","        concat = torch.cat(concat,1)\r\n","        return concat\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["42aea894cfa24564ae95872d68c5f1aa","96c0854c4c2c4858a289afeecc4da16d","93115b68cd88462dad03b34f2ae0099f","16a13fbc561d4b2cb318042d7256eacb","369b4ed7b70a48659ac8345ea36c764f","b8769ef7b2c44124b5a5c881a975c8a6","63f8f28c2b164377a965e7ae1e34d887","74496719b1774851a90dd9e35d630fdd"]},"id":"rUTJ_P5rOuix","executionInfo":{"status":"ok","timestamp":1615961204537,"user_tz":-540,"elapsed":15801,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}},"outputId":"de4144a3-d7fa-481a-b8cb-bd9678aa2c54"},"source":["transforms = T.Compose([\r\n","                        T.RandomCrop((32,32),padding=(4,4)),\r\n","                        T.RandomHorizontalFlip(p=0.5),\r\n","                        T.ToTensor(),\r\n","                        T.Normalize(mean=[0.485, 0.456, 0.406],\r\n","                                     std=[0.229, 0.224, 0.225]),\r\n","                        \r\n","])\r\n","\r\n","trainset = dsets.CIFAR10(root = './datasets',train=True,transform=transforms,download=True)\r\n","testset = dsets.CIFAR10(root='./datasets',train=False,transform=T.Compose([         #T.RandomCrop((32,32),padding=(4,4)),\r\n","                                                                                                                    # T.RandomHorizontalFlip(p=0.5),\r\n","                                                                                                                    T.ToTensor(),\r\n","                                                                                                                    T.Normalize(mean=[0.485,0.456,0.406],\r\n","                                                                                                                                std = [0.229,0.224,0.225])\r\n","]),download=True)\r\n","classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42aea894cfa24564ae95872d68c5f1aa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4zPghdWxZ8e_","executionInfo":{"status":"ok","timestamp":1615961204541,"user_tz":-540,"elapsed":15802,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":[""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWJUN11jPNXV","executionInfo":{"status":"ok","timestamp":1615961204543,"user_tz":-540,"elapsed":15802,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":["trainLoader = torch.utils.data.DataLoader(trainset,batch_size = 128,shuffle = True)\r\n","testLoader = torch.utils.data.DataLoader(testset,batch_size =128,shuffle=False,drop_last=True)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0DNWHFgPNoo","executionInfo":{"status":"ok","timestamp":1615961215549,"user_tz":-540,"elapsed":26806,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n","\r\n","net = InceptionV4()\r\n","net = net.to(device)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cbrX3LqPVRK","executionInfo":{"status":"ok","timestamp":1615961215550,"user_tz":-540,"elapsed":26805,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":["criterion = nn.CrossEntropyLoss().cuda()\r\n","optimizer = optim.SGD(net.parameters(),lr=0.05,momentum=0.9,weight_decay=5e-4)\r\n","# scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.5)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3_S422mQF8G","executionInfo":{"status":"ok","timestamp":1615961215551,"user_tz":-540,"elapsed":26804,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":["\r\n","def check_accuracy(network,testLoader):\r\n","    class_correct = list(0. for i in range(10))\r\n","    class_total = list(0. for i in range(10))\r\n","    with torch.no_grad():\r\n","        for data in testLoader:\r\n","            images,labels = data\r\n","            images = images.cuda()\r\n","            labels = labels.cuda()\r\n","            outputs = network(images)\r\n","            #\r\n","            _,predicted = torch.max(outputs,1)\r\n","            c = (predicted == labels).squeeze()\r\n","            for i in range(128):\r\n","                label = labels[i]\r\n","                class_correct[label] +=c[i].item()\r\n","                class_total[label] +=1\r\n","    accuracy_sum = 0\r\n","    for i in range(10):\r\n","        temp = 100* class_correct[i] / class_total[i]\r\n","        accuracy_sum += temp\r\n","    return accuracy_sum / 10"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"2wwtYsvMQHmo","executionInfo":{"status":"ok","timestamp":1615961215552,"user_tz":-540,"elapsed":26803,"user":{"displayName":"‍이유제[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"08338669511381451862"}}},"source":["\r\n","def show_accuracy(network,testLoader):\r\n","    class_correct = list(0. for i in range(10))\r\n","    class_total = list(0. for i in range(10))\r\n","    with torch.no_grad():\r\n","        for data in testLoader:\r\n","            images,labels = data\r\n","            images = images.cuda()\r\n","            labels = labels.cuda()\r\n","            outputs = network(images)\r\n","            #\r\n","            _,predicted = torch.max(outputs,1)\r\n","            c = (predicted == labels).squeeze()\r\n","            for i in range(128):\r\n","                label = labels[i]\r\n","                class_correct[label] +=c[i].item()\r\n","                class_total[label] +=1\r\n","    accuracy_sum = 0\r\n","    for i in range(10):\r\n","        temp = 100* class_correct[i] / class_total[i]\r\n","        print('Accuracy of %5s : %2d %%'%(classes[i],temp))\r\n","        accuracy_sum += temp\r\n","    print('Accuracy average: ',accuracy_sum / 10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQ4JbMlTQIwY","outputId":"412f031d-579c-4f37-ed43-1a670de4d39c"},"source":["epochs_accuracy_list = []\r\n","epochs_accuracy = 0\r\n","lr = 0.05\r\n","for epoch in range(200):\r\n","    running_loss = 0.0\r\n","    avg_loss=0.0\r\n","    for i,data in enumerate(trainLoader,0):\r\n","        #get the inputs\r\n","        inputs,labels = data\r\n","        inputs,labels = inputs.to(device),labels.to(device)\r\n","        #zero the parameter gradients\r\n","        outputs = net(inputs)\r\n","        loss = criterion(outputs,labels)\r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","        # # print statistics\r\n","        # running_loss += loss.item()\r\n","        # avg_loss += loss.item()\r\n","        # if i%50 ==49:\r\n","        #     print('[%d,%5d] loss: %.3f'%(epoch+1,i+1,running_loss/50))\r\n","        #     running_loss=0.0\r\n","\r\n","    # if abs(pre_avg_loss-avg_loss)<=0.01 and epoch!=0:\r\n","    #     print(\"learning rate 50% reduced.\")\r\n","    #     scheduler.step()\r\n","    acc = check_accuracy(net,testLoader)\r\n","    print(\"epoch: {} | Accuracy: {}\".format(epoch,acc))\r\n","    epochs_accuracy_list.append(acc)\r\n","    \r\n","    if epoch % 5 == 0:\r\n","        show_accuracy(net,testLoader)\r\n","print('Finished Training')\r\n","\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 0 | Accuracy: 9.495390361547651\n","Accuracy of airplane : 17 %\n","Accuracy of automobile : 11 %\n","Accuracy of  bird :  0 %\n","Accuracy of   cat :  0 %\n","Accuracy of  deer :  2 %\n","Accuracy of   dog : 12 %\n","Accuracy of  frog : 27 %\n","Accuracy of horse :  0 %\n","Accuracy of  ship : 23 %\n","Accuracy of truck :  1 %\n","Accuracy average:  9.86584163549\n","epoch: 1 | Accuracy: 9.977785445016918\n","epoch: 2 | Accuracy: 10.37325220660487\n","epoch: 3 | Accuracy: 9.872960169573334\n","epoch: 4 | Accuracy: 9.807968215248936\n","epoch: 5 | Accuracy: 10.469210540643175\n","Accuracy of airplane : 22 %\n","Accuracy of automobile : 12 %\n","Accuracy of  bird :  2 %\n","Accuracy of   cat : 11 %\n","Accuracy of  deer :  0 %\n","Accuracy of   dog :  0 %\n","Accuracy of  frog : 15 %\n","Accuracy of horse :  1 %\n","Accuracy of  ship : 28 %\n","Accuracy of truck :  3 %\n","Accuracy average:  9.868578222727383\n","epoch: 6 | Accuracy: 10.628896352749997\n","epoch: 7 | Accuracy: 10.2311590111447\n","epoch: 8 | Accuracy: 10.196393393632826\n","epoch: 9 | Accuracy: 10.076463601166168\n","epoch: 10 | Accuracy: 9.743217229526941\n","Accuracy of airplane : 53 %\n","Accuracy of automobile : 13 %\n","Accuracy of  bird :  0 %\n","Accuracy of   cat :  5 %\n","Accuracy of  deer :  0 %\n","Accuracy of   dog :  0 %\n","Accuracy of  frog :  1 %\n","Accuracy of horse :  0 %\n","Accuracy of  ship :  2 %\n","Accuracy of truck : 28 %\n","Accuracy average:  10.40436984567195\n","epoch: 11 | Accuracy: 10.119394861200096\n","epoch: 12 | Accuracy: 10.143164910125732\n","epoch: 13 | Accuracy: 9.706135453407267\n","epoch: 14 | Accuracy: 9.959468365014885\n","epoch: 15 | Accuracy: 10.054994984954865\n","Accuracy of airplane :  0 %\n","Accuracy of automobile :  0 %\n","Accuracy of  bird :  0 %\n","Accuracy of   cat : 16 %\n","Accuracy of  deer :  0 %\n","Accuracy of   dog :  0 %\n","Accuracy of  frog : 83 %\n","Accuracy of horse :  0 %\n","Accuracy of  ship :  0 %\n","Accuracy of truck :  0 %\n","Accuracy average:  10.07505516549649\n","epoch: 16 | Accuracy: 9.942798395185557\n","epoch: 17 | Accuracy: 9.99198595787362\n","epoch: 18 | Accuracy: 10.0\n"],"name":"stdout"}]}]}